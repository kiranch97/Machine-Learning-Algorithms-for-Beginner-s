{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPEHNXXbFRpuV8dftSTZIA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiranch97/Machine-Learning-Algorithms-for-Beginner-s/blob/9.-Principal-Component-Analysis-(PCA)/Principal_Component_Analysis_(PCA).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimensionality reduction is accomplished by the use of **Principal Component Analysis (PCA)**. It transforms the data into a new coordinate system, reducing the number of variables while preserving as much of the original data’s variation as possible.\n",
        "\n",
        "The primary components, or axis, that maximize the variance in the data are found using **PCA**. The first principal component captures the most variance, the second principal component (orthogonal to the first) captures the next most, and so on."
      ],
      "metadata": {
        "id": "QrWJT-IWz54G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Metrics:**\n",
        "\n",
        "1. **Explained Variance:** Indicates how much variance in the data is captured by each principal component.\n",
        "\n",
        "2. **Total Explained Variance:** The cumulative variance explained by the selected principal components."
      ],
      "metadata": {
        "id": "u7D272OT0Anz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applying with Sci-kit Learn**\n",
        "\n",
        "The Breast Cancer dataset, which includes characteristics derived from a digital picture of a fine needle aspirate (FNA) of a breast tumor, will be subjected to PCA. Our objective is to minimize the dataset’s dimensionality while maintaining the greatest amount of information.\n",
        "\n",
        "Here are the steps we’ll follow:\n",
        "\n",
        "1. **Load the Breast Cancer Dataset:**\n",
        "\n",
        "The Breast Cancer dataset consists of features computed from digitized images of fine needle aspirates of breast masses. The features are attributes of the cell nuclei that are visible in the picture.\n",
        "\n",
        "2. **Apply PCA:**\n",
        "\n",
        "We initialize PCA with n_components=2, indicating our intention to reduce the dataset to two dimensions. This choice is often made for visualization purposes or as a pre-processing step for other algorithms.\n",
        "We fit PCA to the data X. During this process, PCA identifies the axes (principal components) that account for the most variance in the data.\n",
        "\n",
        "3. **Transform the Data:**\n",
        "\n",
        "The transform method of PCA is used to apply the dimensionality reduction to X. This results in a new dataset X_pca, where each data point is now represented in terms of the two principal components.\n",
        "\n",
        "4. **Evaluate the PCA Transformation:**\n",
        "\n",
        "We evaluate our PCA transformation by looking at the Explained Variance of each principal component. This tells us how much of the data’s total variance is captured by each principal component.\n",
        "The Total Explained Variance is calculated by summing the explained variances of the two principal components. This gives us an overall measure of how much information was preserved in the dimensionality reduction process."
      ],
      "metadata": {
        "id": "neYzveAS0NSY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XdjmqKyJz2pZ"
      },
      "outputs": [],
      "source": [
        "# Import the Libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Breast Cancer dataset\n",
        "breast_cancer = load_breast_cancer()\n",
        "X = breast_cancer.data"
      ],
      "metadata": {
        "id": "s0aSZsqv1ZHa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying PCA\n",
        "pca = PCA(n_components=2)  # Reducing to 2 dimensions for simplicity\n",
        "pca.fit(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "A8FEPHrH1rXs",
        "outputId": "c33e55c7-73d0-419b-868d-72e1c0737af7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(n_components=2)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=2)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming the data\n",
        "X_pca = pca.transform(X)"
      ],
      "metadata": {
        "id": "wIg1z9Sr1vX7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explained Variance\n",
        "explained_variance = pca.explained_variance_ratio_"
      ],
      "metadata": {
        "id": "OhSg5Y-v1ybH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total Explained Variance\n",
        "total_explained_variance = np.sum(explained_variance)"
      ],
      "metadata": {
        "id": "kxQKycJj10T5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Explained variance:\", explained_variance)\n",
        "print(\"Total Explained Variance:\", total_explained_variance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE7OMKkk12zw",
        "outputId": "d970d06b-2ff8-43eb-e408-021f8b855903"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained variance: [0.98204467 0.01617649]\n",
            "Total Explained Variance: 0.9982211613741722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let’s evaluate the results.**\n",
        "\n",
        "**Explained Variance:**\n",
        "\n",
        "1. **First Principal Component:** 98.20%\n",
        "2. **Second Principal Component:** 1.62%\n",
        "3. **Total Explained Variance:** 99.82%\n",
        "\n",
        "These results indicate that by reducing the dataset to just two principal components, we have captured approximately 99.82% of the total variance in the dataset.\n",
        "\n",
        "The first component alone accounts for a significant majority of this variance, which suggests that it captures most of the essential information present in the dataset."
      ],
      "metadata": {
        "id": "OrBkbpfq18zp"
      }
    }
  ]
}